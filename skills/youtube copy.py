# skills/youtube.py
"""
YouTube ì˜ìƒ ì¶”ì²œ ìŠ¤í‚¬

ê¸°ëŠ¥:
- ëª…ì‹œì  ì˜ìƒ ì¶”ì²œ ìš”ì²­ ì²˜ë¦¬ (ì‹œë‚˜ë¦¬ì˜¤ A)
- ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•© ë° ì¤‘ë³µ ì œê±°
- ì¸ë„¤ì¼ + íƒ€ì„ìŠ¤íƒ¬í”„ ë”¥ë§í¬ ì œê³µ
"""

from typing import List, Dict, Any, Optional, Tuple
from collections import defaultdict
from datetime import datetime, timezone, timedelta
import re
import numpy as np
import time

from services.db import youtube_col
from services.embedder import get_embedder

KST = timezone(timedelta(hours=9))

# ============================================================
# ì„¤ì • ìƒìˆ˜
# ============================================================
DEFAULT_LIMIT = 2  # ìµœëŒ€ ì¶”ì²œ ì˜ìƒ ìˆ˜
SIMILARITY_THRESHOLD = 0.35  # ìµœì†Œ ìœ ì‚¬ë„ ì„ê³„ê°’
KEYWORD_BOOST = 0.15  # í‚¤ì›Œë“œ ë§¤ì¹­ ê°€ì¤‘ì¹˜


# ì„±ëŠ¥ ìµœì í™” ì„¤ì • (Flex í‹°ì–´ìš©)
MAX_DOCUMENTS = 3000  # ë¡œë“œí•  ìµœëŒ€ ë¬¸ì„œ ìˆ˜ (5000 â†’ 3000ìœ¼ë¡œ ê°ì†Œ)
CACHE_TTL = 1800  # ìºì‹œ ìœ ì§€ ì‹œê°„ 30ë¶„ (ë” ê¸´ ìºì‹±)
EARLY_STOP_THRESHOLD = 10  # ìƒìœ„ Nê°œë§Œ ìƒì„¸ ë¶„ì„ (ì„±ëŠ¥ í–¥ìƒ)

# ì„ë² ë”© ìºì‹œ (ì „ì—­)
_embedding_cache = {
    "embeddings": None,
    "docs": None,
    "loaded_at": 0,
}

# ============================================================
# ì˜ë„ ê°ì§€
# ============================================================
def is_youtube_intent(query: str) -> bool:
    """YouTube ì˜ìƒ ì¶”ì²œ ì˜ë„ì¸ì§€ íŒë³„"""
    q = (query or "").lower().replace(" ", "")
    keywords = (
        "ì˜ìƒ", "ìœ íŠœë¸Œ", "ë™ì˜ìƒ", "ì¶”ì²œ", "ê³µëµì˜ìƒ",
        "ìœ íŠœë²„", "ë³´ì—¬ì¤˜ì˜ìƒ", "ì°¾ì•„ì¤˜ì˜ìƒ", "youtube",
        "ì˜ìƒìœ¼ë¡œ", "ì˜ìƒìˆ", "ì˜ìƒì•Œë ¤", "ì˜ìƒì¶”ì²œ"
    )
    return any(k in q for k in keywords)


# ============================================================
# ê²€ìƒ‰ ìœ í‹¸ë¦¬í‹°
# ============================================================
def _extract_video_id(doc_id: str) -> str:
    """
    _idì—ì„œ video_id ì¶”ì¶œ
    ì˜ˆ: "video:uu6DSpiL8o0#seg1" â†’ "uu6DSpiL8o0"
    """
    if not doc_id:
        return ""
    # "video:" ì ‘ë‘ì‚¬ ì œê±°
    if doc_id.startswith("video:"):
        doc_id = doc_id[6:]
    # "#seg" ì´í›„ ì œê±°
    if "#" in doc_id:
        doc_id = doc_id.split("#")[0]
    return doc_id


def _get_thumbnail_url(video_id: str, quality: str = "mqdefault") -> str:
    """
    YouTube ì¸ë„¤ì¼ URL ìƒì„±
    quality: default, mqdefault, hqdefault, sddefault, maxresdefault
    """
    if not video_id:
        return ""
    return f"https://img.youtube.com/vi/{video_id}/{quality}.jpg"


def _format_timestamp(seconds: float) -> str:
    """ì´ˆë¥¼ MM:SS ë˜ëŠ” HH:MM:SS í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    if seconds is None or seconds < 0:
        return ""
    
    seconds = int(seconds)
    hours = seconds // 3600
    minutes = (seconds % 3600) // 60
    secs = seconds % 60
    
    if hours > 0:
        return f"{hours}:{minutes:02d}:{secs:02d}"
    return f"{minutes}:{secs:02d}"


def _tokenize_query(query: str) -> List[str]:
    """ì§ˆë¬¸ì—ì„œ í‚¤ì›Œë“œ í† í° ì¶”ì¶œ"""
    # ì˜ë„ì–´/ë¶ˆìš©ì–´ ì œê±°
    stopwords = (
        "ì˜ìƒ", "ìœ íŠœë¸Œ", "ë™ì˜ìƒ", "ì¶”ì²œ", "ì•Œë ¤ì¤˜", "ë³´ì—¬ì¤˜",
        "í•´ì¤˜", "ìˆì–´", "ì°¾ì•„ì¤˜", "ê³µëµ", "ì–´ë–»ê²Œ", "ë­ì•¼"
    )
    q = query.lower()
    for sw in stopwords:
        q = q.replace(sw, " ")
    
    # í† í° ì¶”ì¶œ
    tokens = re.findall(r"[ê°€-í£A-Za-z0-9]+", q)
    return [t for t in tokens if len(t) >= 2]


# ============================================================
# ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•©
# ============================================================
def merge_video_segments(segments: List[Dict]) -> List[Dict]:
    """
    ë™ì¼ ì˜ìƒì˜ ì„¸ê·¸ë¨¼íŠ¸ë“¤ì„ ë³‘í•©í•˜ì—¬ ì˜ìƒ ë‹¨ìœ„ë¡œ ê·¸ë£¹í™”
    
    ì…ë ¥: ê°œë³„ ì„¸ê·¸ë¨¼íŠ¸ ë¦¬ìŠ¤íŠ¸
    ì¶œë ¥: ì˜ìƒ ë‹¨ìœ„ë¡œ ë³‘í•©ëœ ë¦¬ìŠ¤íŠ¸ (ìµœê³  ì ìˆ˜ ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ ìœ ì§€)
    """
    if not segments:
        return []
    
    # video_id ê¸°ì¤€ ê·¸ë£¹í™”
    video_groups: Dict[str, List[Dict]] = defaultdict(list)
    
    for seg in segments:
        doc_id = str(seg.get("_id", ""))
        video_id = _extract_video_id(doc_id)
        if video_id:
            video_groups[video_id].append(seg)
    
    # ê° ì˜ìƒë³„ë¡œ ìµœê³  ì ìˆ˜ ì„¸ê·¸ë¨¼íŠ¸ ì„ íƒ + ê´€ë ¨ ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ ìœ ì§€
    merged = []
    for video_id, segs in video_groups.items():
        # ì ìˆ˜ìˆœ ì •ë ¬
        segs_sorted = sorted(segs, key=lambda x: x.get("score", 0), reverse=True)
        best_seg = segs_sorted[0]
        
        # ê´€ë ¨ ì„¸ê·¸ë¨¼íŠ¸ ì¸ë±ìŠ¤ ìˆ˜ì§‘
        segment_indices = sorted(set(
            s.get("segment_idx") for s in segs if s.get("segment_idx") is not None
        ))
        
        merged.append({
            "video_id": video_id,
            "title": best_seg.get("title", ""),
            "channel_title": best_seg.get("channel_title", ""),
            "url": best_seg.get("url", ""),
            "segment_url": best_seg.get("segment_url", ""),
            "segment_start": best_seg.get("segment_start"),
            "segment_end": best_seg.get("segment_end"),
            "segment_text": best_seg.get("segment_text", ""),
            "published_at": best_seg.get("published_at"),
            "duration": best_seg.get("duration", ""),
            "tags": best_seg.get("tags", []),
            "score": best_seg.get("score", 0.0),
            "keyword_match": best_seg.get("keyword_match", False),
            "matched_segments": segment_indices,
            "thumbnail": _get_thumbnail_url(video_id),
        })
    
    # ì ìˆ˜ìˆœ ì •ë ¬
    merged.sort(key=lambda x: x["score"], reverse=True)
    return merged


# ============================================================
# YouTube ê²€ìƒ‰
# ============================================================
async def search_youtube_videos(
    query: str,
    limit: int = DEFAULT_LIMIT,
    score_threshold: float = SIMILARITY_THRESHOLD,
) -> List[Dict]:
    """
    YouTube ì˜ìƒ ê²€ìƒ‰ (Flex í‹°ì–´ ìµœì í™”)
    
    ìµœì í™” ê¸°ë²•:
    1. ì„ë² ë”©/ë¬¸ì„œ 30ë¶„ ìºì‹± â†’ ë°˜ë³µ ê²€ìƒ‰ ì‹œ ì¦‰ì‹œ ì‘ë‹µ
    2. ìµœëŒ€ 3000ê°œ ë¬¸ì„œë§Œ ë¡œë“œ â†’ ë©”ëª¨ë¦¬/ì‹œê°„ ì ˆì•½
    3. ìµœì‹  ì˜ìƒ ìš°ì„  ì •ë ¬ â†’ ê´€ë ¨ì„± ë†’ì€ ê²°ê³¼
    4. ìƒìœ„ 50ê°œë§Œ ìƒì„¸ ë¶„ì„ â†’ ì¡°ê¸° ì¢…ë£Œë¡œ ì„±ëŠ¥ í–¥ìƒ
    5. numpy ì—°ì‚° ìµœì í™” â†’ ë¹ ë¥¸ ìœ ì‚¬ë„ ê³„ì‚°
    """
    embedder = get_embedder()
    
    # ì§ˆì˜ ì„ë² ë”©
    q_emb = embedder.encode(query, convert_to_numpy=True).astype(np.float32)
    if q_emb.ndim > 1:
        q_emb = q_emb[0]
    
    # í‚¤ì›Œë“œ í† í°
    query_tokens = _tokenize_query(query)
    
    # âœ… ìºì‹œ í™•ì¸ (30ë¶„ ìœ íš¨)
    now = time.time()
    if (_embedding_cache["embeddings"] is None or 
        (now - _embedding_cache["loaded_at"] > CACHE_TTL)):
        
        print(f"[INFO] ì„ë² ë”© ìºì‹œ ê°±ì‹  ì¤‘... (ìµœëŒ€ {MAX_DOCUMENTS}ê°œ ë¬¸ì„œ)")
        
        try:
            # âœ… ìµœì‹  ì˜ìƒ ìš°ì„ , ìµœëŒ€ 3000ê°œë§Œ ë¡œë“œ
            docs = await youtube_col.find(
                {"embedding": {"$exists": True}},
                {
                    "_id": 1, "title": 1, "channel_title": 1,
                    "url": 1, "segment_url": 1, "segment_idx": 1,
                    "segment_start": 1, "segment_end": 1, "segment_text": 1,
                    "published_at": 1, "duration": 1, "tags": 1, "embedding": 1,
                }
            ).sort("published_at", -1).to_list(length=MAX_DOCUMENTS)
        except Exception as e:
            print(f"[ERROR] youtube_col search failed: {e}")
            return []
        
        if not docs:
            return []
        
        # ì„ë² ë”© ì¶”ì¶œ
        valid_docs = []
        embeddings = []
        
        for doc in docs:
            emb = doc.get("embedding")
            if emb is not None:
                valid_docs.append(doc)
                embeddings.append(np.asarray(emb, dtype=np.float32))
        
        if not valid_docs:
            return []
        
        emb_matrix = np.vstack(embeddings).astype(np.float32)
        
        # âœ… ìºì‹œ ì €ì¥
        _embedding_cache.update({
            "embeddings": emb_matrix,
            "docs": valid_docs,
            "loaded_at": now
        })
        
        print(f"[INFO] ìºì‹œ ê°±ì‹  ì™„ë£Œ: {len(valid_docs)}ê°œ ë¬¸ì„œ")
    
    # ìºì‹œì—ì„œ ë¡œë“œ
    emb_matrix = _embedding_cache["embeddings"]
    cached_docs = _embedding_cache["docs"]
    
    # âœ… ìµœì í™”ëœ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
    q_norm = q_emb / (np.linalg.norm(q_emb) + 1e-12)
    emb_norms = emb_matrix / (np.linalg.norm(emb_matrix, axis=1, keepdims=True) + 1e-12)
    similarities = emb_norms @ q_norm
    
    # âœ… ì¡°ê¸° ì¢…ë£Œ: ìƒìœ„ Nê°œë§Œ ì„ íƒ (ì „ì²´ ì •ë ¬ X)
    if len(similarities) > EARLY_STOP_THRESHOLD:
        top_indices = np.argpartition(similarities, -EARLY_STOP_THRESHOLD)[-EARLY_STOP_THRESHOLD:]
        top_indices = top_indices[np.argsort(similarities[top_indices])[::-1]]
    else:
        top_indices = np.argsort(similarities)[::-1]
    
    # ìƒìœ„ ë¬¸ì„œë§Œ ë³µì‚¬
    docs = []
    for idx in top_indices:
        doc = dict(cached_docs[idx])  # ì–•ì€ ë³µì‚¬
        doc["score"] = float(similarities[idx])
        docs.append(doc)
    
    # âœ… í‚¤ì›Œë“œ ë¶€ìŠ¤íŒ… (íƒœê·¸ ê°•í™”)
    for doc in docs:
        title = (doc.get("title") or "").lower()
        text = (doc.get("segment_text") or "").lower()
        tags = [t.lower() for t in (doc.get("tags") or [])]
        
        match_count = 0
        tag_exact_match = False
        
        for token in query_tokens:
            if token in title:
                match_count += 2  # ì œëª© ìš°ì„ 
            elif token in text:
                match_count += 1
            elif any(token in tag for tag in tags):
                match_count += 1.5  # íƒœê·¸ ê°€ì¤‘ì¹˜ ì¦ê°€
                if token in tags:  # ì™„ì „ ì¼ì¹˜
                    tag_exact_match = True
        
        if match_count > 0:
            boost = min(KEYWORD_BOOST * match_count, 0.3)
            if tag_exact_match:
                boost += 0.1  # íƒœê·¸ ì •í™• ì¼ì¹˜ ë³´ë„ˆìŠ¤
            doc["score"] = min(1.0, doc.get("score", 0) + boost)
            doc["keyword_match"] = True
        else:
            doc["keyword_match"] = False
    
    # ì„ê³„ê°’ í•„í„°ë§
    filtered = [d for d in docs if d.get("score", 0) >= score_threshold]
    
    if not filtered:
        return []
    
    # ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•©
    merged = merge_video_segments(filtered)
    
    return merged[:limit]


# ============================================================
# ì‘ë‹µ ìƒì„±
# ============================================================
def _build_video_card_html(video: Dict, show_timestamp: bool = True) -> str:
    """ê°œë³„ ì˜ìƒ ì¹´ë“œ HTML ìƒì„±"""
    title = video.get("title", "ì˜ìƒ")
    channel = video.get("channel_title", "")
    thumbnail = video.get("thumbnail", "")
    score = video.get("score", 0)
    
    # ë§í¬ ê²°ì •: íƒ€ì„ìŠ¤íƒ¬í”„ ìˆìœ¼ë©´ segment_url, ì—†ìœ¼ë©´ url
    segment_start = video.get("segment_start")
    segment_url = video.get("segment_url", "")
    base_url = video.get("url", "")
    
    # íƒ€ì„ìŠ¤íƒ¬í”„ í‘œì‹œ ì—¬ë¶€ ê²°ì •
    timestamp_html = ""
    link_url = base_url
    
    if show_timestamp and segment_start is not None and segment_url:
        link_url = segment_url
        ts_formatted = _format_timestamp(segment_start)
        if ts_formatted:
            timestamp_html = f'''
            <div style="font-size:12px;color:#dc2626;margin-top:4px">
                â±ï¸ {ts_formatted} ë¶€í„° ê´€ë ¨ ë‚´ìš©
            </div>
            '''
    
    # ì œëª© ê¸¸ì´ ì œí•œ
    display_title = title[:50] + "..." if len(title) > 50 else title
    
    return f'''
    <div style="display:flex;gap:12px;padding:12px;border:1px solid #e5e7eb;border-radius:12px;background:#fafafa;margin-bottom:10px">
        <a href="{link_url}" target="_blank" rel="noopener" style="flex-shrink:0">
            <img src="{thumbnail}" alt="ì¸ë„¤ì¼" 
                 style="width:120px;height:68px;object-fit:cover;border-radius:8px;border:1px solid #e5e7eb"/>
        </a>
        <div style="flex:1;min-width:0">
            <a href="{link_url}" target="_blank" rel="noopener" 
               style="text-decoration:none;color:#111827;font-weight:600;font-size:14px;line-height:1.3;display:block">
                {display_title}
            </a>
            <div style="font-size:12px;color:#6b7280;margin-top:4px">
                {channel}
            </div>
            {timestamp_html}
        </div>
    </div>
    '''


def build_youtube_response(
    videos: List[Dict],
    query: str,
) -> Dict[str, Any]:
    """
    YouTube ì¶”ì²œ ì‘ë‹µ ìƒì„±
    
    Returns:
        {
            "type": "youtube",
            "answer": í…ìŠ¤íŠ¸ ì‘ë‹µ,
            "answer_html": HTML ì¹´ë“œ UI,
            "videos": ì˜ìƒ ë©”íƒ€ë°ì´í„° ë¦¬ìŠ¤íŠ¸,
        }
    """
    if not videos:
        return {
            "type": "youtube",
            "answer": "ì£„ì†¡í•´ìš”, ê´€ë ¨ ì˜ìƒì„ ì°¾ì§€ ëª»í–ˆì–´ìš”. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•´ ë³´ì‹œê² ì–´ìš”?",
            "answer_html": None,
            "videos": [],
        }
    
    # í…ìŠ¤íŠ¸ ì‘ë‹µ
    if len(videos) == 1:
        answer_text = f"'{videos[0]['title'][:30]}...' ì˜ìƒì„ ì¶”ì²œë“œë ¤ìš”!"
    else:
        answer_text = f"ê´€ë ¨ ì˜ìƒ {len(videos)}ê°œë¥¼ ì°¾ì•˜ì–´ìš”. í™•ì¸í•´ ë³´ì„¸ìš”!"
    
    # HTML ì¹´ë“œ ìƒì„±
    cards_html = "".join(_build_video_card_html(v) for v in videos)
    
    wrapper_html = f'''
    <div style="max-width:480px">
        <div style="font-size:14px;color:#374151;margin-bottom:12px">
            ğŸ“º ì¶”ì²œ ì˜ìƒ
        </div>
        {cards_html}
    </div>
    '''
    
    return {
        "type": "youtube",
        "answer": answer_text,
        "answer_html": wrapper_html.strip(),
        "videos": videos,
    }


# ============================================================
# ë©”ì¸ í•¸ë“¤ëŸ¬
# ============================================================
async def answer_youtube_recommend(query: str) -> Dict[str, Any]:
    """
    YouTube ì˜ìƒ ì¶”ì²œ ë©”ì¸ í•¸ë“¤ëŸ¬
    """
    # ê²€ìƒ‰ ì‹¤í–‰
    videos = await search_youtube_videos(
        query=query,
        limit=DEFAULT_LIMIT,
        score_threshold=SIMILARITY_THRESHOLD,
    )
    
    # ì‘ë‹µ ìƒì„±
    return build_youtube_response(videos, query)


# ============================================================
# ë³´ì¡° í•¨ìˆ˜: QA ë³´ì¶© ì˜ìƒ (ì‹œë‚˜ë¦¬ì˜¤ Bìš© - ë‚˜ì¤‘ì— ì‚¬ìš©)
# ============================================================
async def get_supplementary_videos(
    query: str,
    limit: int = 1,
    score_threshold: float = 0.45,  # ë³´ì¶©ìš©ì€ ë” ì—„ê²©í•˜ê²Œ
) -> List[Dict]:
    """
    QA ì‘ë‹µì— ë³´ì¶©í•  ê´€ë ¨ ì˜ìƒ ê²€ìƒ‰
    
    ì‹œë‚˜ë¦¬ì˜¤ B: í…ìŠ¤íŠ¸ ë‹µë³€ + ë³´ì¶© ì˜ìƒ
    - ê´€ë ¨ ì˜ìƒì´ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    - ì ìˆ˜ê°€ ë‚®ìœ¼ë©´ ì¶”ì²œí•˜ì§€ ì•ŠìŒ
    """
    videos = await search_youtube_videos(
        query=query,
        limit=limit,
        score_threshold=score_threshold,
    )
    return videos


def build_supplementary_html(videos: List[Dict]) -> Optional[str]:
    """
    ë³´ì¶© ì˜ìƒ HTML ìƒì„± (ì‹œë‚˜ë¦¬ì˜¤ Bìš©)
    
    ì˜ìƒì´ ì—†ìœ¼ë©´ None ë°˜í™˜
    """
    if not videos:
        return None
    
    cards_html = "".join(_build_video_card_html(v) for v in videos)
    
    return f'''
    <div style="margin-top:16px;padding-top:12px;border-top:1px solid #e5e7eb">
        <div style="font-size:13px;color:#6b7280;margin-bottom:8px">
            ğŸ“º ê´€ë ¨ ì˜ìƒë„ ì°¸ê³ í•´ë³´ì„¸ìš”
        </div>
        {cards_html}
    </div>
    '''.strip()